{"cells":[{"cell_type":"markdown","metadata":{"id":"7hq02MAexQov"},"source":["# Regression CatBoost"]},{"cell_type":"markdown","source":["## Cloner la branche contenant le dateset le le code qui va avec."],"metadata":{"id":"eaB5K5Vnv_Zr"}},{"cell_type":"code","source":["!rm -rf ActuarialThesis\n","!git clone https://github.com/aderdouri/ActuarialThesis.git\n","%ls -ltr ActuarialThesis"],"metadata":{"id":"MIzuG9lLv-qB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir ActuarialThesis/plots_rgr\n","!ls -ltr ActuarialThesis/plots_rgr"],"metadata":{"id":"_rUJ_QVHwJ6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ajouter le répértoire src\n","import sys\n","sys.path.insert(0,'./ActuarialThesis/src/')"],"metadata":{"id":"WNxNTNl3wPGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import installHelper"],"metadata":{"id":"gQK3czwfwQn0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(list(dir(installHelper)))"],"metadata":{"id":"na4NiGkKwSA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -ltr"],"metadata":{"id":"Dq4LUfuawTqZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Installer les packages nécéssaires"],"metadata":{"id":"afsLDKQ0wI8A"}},{"cell_type":"code","source":["installHelper.installALL()"],"metadata":{"id":"ZsHliYDgwYKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# On doit trouver tous les packages mentionés dans le grep\n","!pip list -v | grep -e catboost -e 'imbalanced-learn' -e 'optuna' -e 'catboost' -e 'lime' -e 'shap'"],"metadata":{"id":"jPdM42hywbNJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Importer les packages nécéssaires"],"metadata":{"id":"0O3HrtEjwc5N"}},{"cell_type":"code","source":["from helper import *"],"metadata":{"id":"NwMKtyB7wgPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Appliquer le theme par défaut\n","sns.set_theme()"],"metadata":{"id":"WWAzE3wBwiOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Partir du dataset déjé encodé."],"metadata":{"id":"l3Nm2HxiwfqU"}},{"cell_type":"code","source":["# Partir du dataset déja encodé.\n","df = pd.read_csv('ActuarialThesis/Data/encodedBASEAUTO.csv')\n","df.head()"],"metadata":{"id":"ZbHLYQArwqKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.drop('CHARGE', axis=1)\n","y = df['CHARGE']"],"metadata":{"id":"WaIlOIpqzn2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tout d'abord, nous séparons la cible du cadre de données avec des caractéristiques (df -> X, y).\n","\n","Ensuite, nous divisons les données en ensembles train/val/test dans le rapport 60:20:20. L'idée est que nous utiliserons l'ensemble train pour entraîner nos modèles, l'ensemble val pour les valider et l'ensemble test pour calculer l'erreur finale du mélange. L'ensemble de test sera donc constitué de données totalement inédites.\n","\n","Pour ce faire, utilisez un train_test_split régulier de sklearn pour diviser X et y en parties train et val/test dans le ratio 60:40. Ensuite, utilisez à nouveau train_test_split, mais pour diviser la partie val/test obtenue en validation et test dans un rapport 50:50. Dans chaque application de train_test_split, utilisez random_state=13 et les autres valeurs de paramètres par défaut.\n","\n","Au final, vous devriez obtenir X_train, X_val, X_test avec les formes suivantes, respectivement : (xxx, xxx), (xxx, xx), (xxx, xxx). La même logique s'applique à y_train, y_val, y_test."],"metadata":{"id":"IN1fZnjrzZRL"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=13)\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=13)"],"metadata":{"id":"oFixPQiNzPfO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from catboost import CatBoostRegressor\n","from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n","import optuna"],"metadata":{"id":"4XZs7RFdzF6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SAMPLE_RATE = 0.4\n","RANDOM_SEED = 1\n","EARLY_STOPPING_ROUND = 100"],"metadata":{"id":"hCenXCFbRdvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2,log=True),\n","def objective(trial):\n","    param = {}\n","    param['loss_function'] = trial.suggest_categorical(\"loss_function\", ['RMSE', 'Tweedie:variance_power=1.9'])\n","    param['learning_rate'] = trial.suggest_float(\"learning_rate\", 0.001, 0.02, log=True)\n","    param['depth'] = trial.suggest_int('depth', 9, 15)\n","    param['l2_leaf_reg'] = trial.suggest_float('l2_leaf_reg', 1.0, 5.5, log=True)\n","    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n","    param['grow_policy'] = trial.suggest_categorical('grow_policy', ['Depthwise']) \n","    param['iterations'] = trial.suggest_categorical('iterations', [10000])\n","    param['use_best_model'] = trial.suggest_categorical('use_best_model', [True]) \n","    param['eval_metric'] = trial.suggest_categorical('eval_metric', ['RMSE'])\n","    param['od_type'] = trial.suggest_categorical('od_type', ['Iter'])\n","    param['od_wait'] = trial.suggest_categorical('od_wait', [20])\n","    param['random_state'] = trial.suggest_categorical('random_state', [RANDOM_SEED])\n","    param['logging_level'] = trial.suggest_categorical('logging_level', ['Silent'])\n","    \n","    regressor = CatBoostRegressor(**param)\n","\n","    regressor.fit(X_train, y_train,\n","                  eval_set=[(X_val, y_val)],\n","                  early_stopping_rounds=EARLY_STOPPING_ROUND)\n","    \n","    y_pred = regressor.predict(X_val)\n","    loss = mean_squared_error(y_val, y_pred, squared=False)\n","    return loss"],"metadata":{"id":"Kq_NhW2J0Jr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","study = optuna.create_study(study_name=f'catboost-seed{RANDOM_SEED}')\n","study.optimize(objective, n_trials=3, n_jobs=-1) #, timeout=24000)"],"metadata":{"id":"Mn3-1OVdFi8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Number of finished trials: \", len(study.trials))\n","print(\"Best trial:\")\n","trial = study.best_trial\n","hp_cb = study.best_params\n","\n","# Print the objective value and the set of hyperparameters of the best trial\n","print(\"  Value: {}\".format(trial.value))\n","print(\"  Params: \")\n","for key, value in trial.params.items():\n","    print(\"    {}: {}\".format(key, value))"],"metadata":{"id":"JzGe-iGQFmFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import kaleido\n","fig = optuna.visualization.plot_param_importances(study)\n","fig.write_image(\"./ActuarialThesis/plots_rgr/myCatBoostRegressorParamImportances.pdf\")\n","fig.show()"],"metadata":{"id":"WUHoqkZc57P-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#optuna.visualization.plot_edf(study)"],"metadata":{"id":"oLlT0YddWoOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimized_cb_rgr = CatBoostRegressor(**hp_cb)\n","optimized_cb_rgr.fit(X_train, y_train,\n","                     eval_set=[(X_val, y_val)], \n","                     early_stopping_rounds=50, \n","                     verbose=False,\n","                     )"],"metadata":{"id":"CbtByQ2h10Wx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_cb_rgr = optimized_cb_rgr.predict(X_test)\n","print(\"Best rmse:\", mean_squared_error(y_pred_cb_rgr, y_test, squared=False))\n","print(\"R2 using CatBoost: \", r2_score(y_test, y_pred_cb_rgr ))"],"metadata":{"id":"--WshRKMHmxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_importances = zip(X_train.columns, optimized_cb_rgr.feature_importances_)\n","feature_importances = sorted(feature_importances, key=lambda x: x[1])\n","feature_importances = pd.DataFrame(feature_importances, columns=['feature', 'importance'])\n","\n","fig = plt.gcf()\n","fig.figure.set_size_inches(20, 6)\n","plt.title('Feature importances for CatBoostClassifier')\n","sns.barplot(x='importance', y='feature', data=feature_importances[-10:])\n","plt.savefig('./ActuarialThesis/plots_rgr/myCatBoostRegressorFeatureImportance.pdf')"],"metadata":{"id":"tOR7cNtwXrZ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create two subplots and unpack the output array immediately\n","fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True,  figsize=(15, 4))\n","\n","# Create scatter plot with actual and predicted values\n","sns.scatterplot(ax=ax1, x=y_test, y=y_pred_cb_rgr)\n","ax1.set_xlabel('Actual Values')\n","ax1.set_ylabel('Predicted Values')\n","ax1.set_title('Actual vs Predicted Values')\n","\n","# Create regression plot with actual and predicted values\n","sns.regplot(ax=ax2, x=y_test, y=y_pred_cb_rgr, scatter_kws={'s': 10}, line_kws={'color': 'red'})\n","ax2.set_xlabel('Predicted Values')\n","ax2.set_ylabel('Residuals')\n","ax2.set_title('Residual Plot of Actual vs Predicted Values');\n","\n","fig.savefig('./ActuarialThesis/plots_rgr/myCatBoostRegressorActualvsPredicted.pdf')"],"metadata":{"id":"AYzkU5mw6pXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#filename = \"optimized_cb_rgr.pkl\"\n","#pickle.dump(optimized_cb_rgr, open(filename, \"wb\"))"],"metadata":{"id":"Ci7Oy_P249o6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from joblib import dump, load"],"metadata":{"id":"vCkB10P4oN36"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving model\n","dump(optimized_cb_rgr, './ActuarialThesis/Models/optimized_cb_rgr.joblib') "],"metadata":{"id":"7C9SRlNhoOeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading model\n","my_optimized_cb_rgr = load('./ActuarialThesis/Models/optimized_cb_rgr.joblib') "],"metadata":{"id":"eHI6JyFvoVKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_cb_rgr = my_optimized_cb_rgr.predict(X_test)\n","print(\"Best rmse:\", mean_squared_error(y_pred_cb_rgr, y_test, squared=False))\n","print(\"R2 using CatBoost: \", r2_score(y_test, y_pred_cb_rgr ))"],"metadata":{"id":"8zp4ztC5qQRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.initjs()"],"metadata":{"id":"0s0JGoC8qcow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Explain the model's predictions using SHAP values\n","explainer = shap.TreeExplainer(optimized_cb_rgr)\n","shap_values = explainer.shap_values(X_test)"],"metadata":{"id":"AXuC4-zosL6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.force_plot(base_value=explainer.expected_value,\n","                shap_values=shap_values[-1, :], \n","                features=X_test.iloc[-1, :],\n","                matplotlib=True,\n","                show=False)\n","plt.savefig('./ActuarialThesis/plots_rgr/myCatBoostRegressorSHAP01.pdf', format='pdf', dpi=600, bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"eVvNzvnVqwGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.summary_plot(shap_values, X_test, show=False)\n","plt.savefig('./ActuarialThesis/plots_rgr/myCatBoostRegressorSHAP02.pdf', format='pdf', dpi=600, bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"VXXM9pENyc8T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LIME has one explainer for all the models\n","explainer = LimeTabularExplainer(X_test.values, \n","                                 feature_names=X_train.columns.values.tolist(),\n","                                 class_names=['MEDV'], \n","                                 verbose=True, \n","                                 mode='regression')"],"metadata":{"id":"DJ_lTDST2DuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Choose the 5th instance and use it to predict the results\n","j = 5\n","exp = explainer.explain_instance(X_test.values[j], optimized_cb_rgr.predict, num_features=6)"],"metadata":{"id":"V_SC2FVH2gXT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show the predictions\n","exp.show_in_notebook(show_table=True)"],"metadata":{"id":"F79Lxyd-2yDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exp.as_pyplot_figure()\n","plt.savefig('./ActuarialThesis/plots_rgr/myCatBoostRegressorLime.pdf', format='pdf', dpi=600, bbox_inches='tight')\n","plt.show();"],"metadata":{"id":"rBR3qzlC31uj"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","private_outputs":true},"coursera":{"schema_names":["ensembling-techniques-task-week-2"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}