{"cells":[{"cell_type":"markdown","metadata":{"id":"7hq02MAexQov"},"source":["# Regression XGBoost"]},{"cell_type":"markdown","source":["## Cloner la branche contenant le dateset le le code qui va avec."],"metadata":{"id":"eaB5K5Vnv_Zr"}},{"cell_type":"code","source":["!rm -rf ActuarialThesis\n","!git clone https://github.com/aderdouri/ActuarialThesis.git\n","%ls -ltr ActuarialThesis"],"metadata":{"id":"MIzuG9lLv-qB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir ActuarialThesis/plots_rgr\n","!ls -ltr ActuarialThesis/plots_rgr"],"metadata":{"id":"_rUJ_QVHwJ6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ajouter le répértoire src\n","import sys\n","sys.path.insert(0,'./ActuarialThesis/src/')"],"metadata":{"id":"WNxNTNl3wPGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import installHelper"],"metadata":{"id":"gQK3czwfwQn0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(list(dir(installHelper)))"],"metadata":{"id":"na4NiGkKwSA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -ltr"],"metadata":{"id":"Dq4LUfuawTqZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Installer les packages nécéssaires"],"metadata":{"id":"afsLDKQ0wI8A"}},{"cell_type":"code","source":["installHelper.installALL()"],"metadata":{"id":"ZsHliYDgwYKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# On doit trouver tous les packages mentionés dans le grep\n","!pip list -v | grep -e catboost -e 'imbalanced-learn' -e 'optuna' -e 'catboost' -e 'lime' -e 'shap'"],"metadata":{"id":"jPdM42hywbNJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Importer les packages nécéssaires"],"metadata":{"id":"0O3HrtEjwc5N"}},{"cell_type":"code","source":["from helper import *"],"metadata":{"id":"NwMKtyB7wgPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Appliquer le theme par défaut\n","sns.set_theme()"],"metadata":{"id":"WWAzE3wBwiOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Partir du dataset déjé encodé."],"metadata":{"id":"l3Nm2HxiwfqU"}},{"cell_type":"code","source":["# Partir du dataset déja encodé.\n","df = pd.read_csv('ActuarialThesis/Data/encodedBASEAUTO.csv')\n","df.head()"],"metadata":{"id":"ZbHLYQArwqKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.drop('CHARGE', axis=1)\n","y = df['CHARGE']"],"metadata":{"id":"WaIlOIpqzn2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tout d'abord, nous séparons la cible du cadre de données avec des caractéristiques (df -> X, y).\n","\n","Ensuite, nous divisons les données en ensembles train/val/test dans le rapport 60:20:20. L'idée est que nous utiliserons l'ensemble train pour entraîner nos modèles, l'ensemble val pour les valider et l'ensemble test pour calculer l'erreur finale du mélange. L'ensemble de test sera donc constitué de données totalement inédites.\n","\n","Pour ce faire, utilisez un train_test_split régulier de sklearn pour diviser X et y en parties train et val/test dans le ratio 60:40. Ensuite, utilisez à nouveau train_test_split, mais pour diviser la partie val/test obtenue en validation et test dans un rapport 50:50. Dans chaque application de train_test_split, utilisez random_state=13 et les autres valeurs de paramètres par défaut.\n","\n","Au final, vous devriez obtenir X_train, X_val, X_test avec les formes suivantes, respectivement : (23786, 58), (7929, 58), (7929, 58). La même logique s'applique à y_train, y_val, y_test."],"metadata":{"id":"IN1fZnjrzZRL"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=13)\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=13)"],"metadata":{"id":"oFixPQiNzPfO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from xgboost import XGBRegressor\n","from sklearn.metrics import mean_squared_error"],"metadata":{"id":"4XZs7RFdzF6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xgb_rgr = XGBRegressor(objective='reg:squarederror', \n","                       n_estimators=200, \n","                       learning_rate=0.01, \n","                       max_depth=5, \n","                       random_state=13)\n","\n","xgb_rgr.fit(X_train, y_train, \n","        eval_set=[(X_val, y_val)], \n","        early_stopping_rounds=50, \n","        verbose=False)\n","\n","y_pred_xgb_rgr = xgb_rgr.predict(X_val)\n","rmse = mean_squared_error(y_val, y_pred_xgb_rgr, squared=False)\n","print(\"RMSE: %.5f\" % rmse)"],"metadata":{"id":"Kq_NhW2J0Jr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bsf1mDiPL-dX"},"outputs":[],"source":["xgb_rgr = XGBRegressor(objective='reg:tweedie',\n","                       tweedie_variance_power=1.7,\n","                       n_estimators=200, \n","                       learning_rate=0.01, \n","                       max_depth=5, \n","                       random_state=13\n","                       )\n","\n","xgb_rgr.fit(X_train, y_train, \n","        eval_set=[(X_val, y_val)], \n","        early_stopping_rounds=50, \n","        verbose=False)\n","\n","y_pred_xgb_rgr = xgb_rgr.predict(X_val)\n","rmse = mean_squared_error(y_val, y_pred_xgb_rgr, squared=False)\n","print(\"RMSE: %.5f\" % rmse)"]},{"cell_type":"code","source":["# Create two subplots and unpack the output array immediately\n","fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True,  figsize=(15, 4))\n","\n","# Create scatter plot with actual and predicted values\n","sns.scatterplot(ax=ax1, x=y_val, y=y_pred_xgb_rgr)\n","ax1.set_xlabel('Actual Values')\n","ax1.set_ylabel('Predicted Values')\n","ax1.set_title('Actual vs Predicted Values')\n","\n","# Create regression plot with actual and predicted values\n","sns.regplot(ax=ax2, x=y_val, y=y_pred_xgb_rgr, scatter_kws={'s': 10}, line_kws={'color': 'red'})\n","ax2.set_xlabel('Predicted Values')\n","ax2.set_ylabel('Residuals')\n","ax2.set_title('Residual Plot of Actual vs Predicted Values');"],"metadata":{"id":"pub4_rIAhOoL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SAMPLE_RATE = 0.4\n","RANDOM_SEED = 1\n","EARLY_STOPPING_ROUND = 100"],"metadata":{"id":"qa-yTEGBBsSl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","    param = {\n","        'objective': trial.suggest_categorical('objective', ['reg:squarederror', 'reg:tweedie']),\n","        'max_depth': trial.suggest_int('max_depth', 1, 10),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n","        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n","        'subsample': trial.suggest_float('subsample', 0.01, 1.0),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0),\n","        #'random_state': trial.suggest_int('random_state', 1, 1000)\n","    }\n","\n","    if param[\"objective\"] == \"reg:tweedie\":\n","        param[\"tweedie_variance_power\"] = trial.suggest_float(\"tweedie_variance_power\", 1.1, 1.9)\n","\n","    regressor = XGBRegressor(**param,\n","                             early_stopping_rounds=EARLY_STOPPING_ROUND\n","                             )\n","\n","    regressor.fit(X_train, y_train,\n","                  eval_set=[(X_val, y_val)],\n","                  #early_stopping_rounds=EARLY_STOPPING_ROUND,\n","                  verbose=False)\n","\n","    y_pred = regressor.predict(X_val)\n","    return mean_squared_error(y_val, y_pred, squared=False)"],"metadata":{"id":"kEoMCsFa94EU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the study\n","study = optuna.create_study(direction='minimize', study_name='xgb_regression')\n","study.optimize(objective, n_trials=1000)"],"metadata":{"id":"kZ5j0tWX1a8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xgx_reg_hp = study.best_params\n","print(\"Number of finished trials: {}\".format(len(study.trials)))\n","print(\"Best trial:\")\n","trial = study.best_trial\n","print(\"  Value: {}\".format(trial.value))\n","print(\"  Params: \")\n","for key, value in trial.params.items():\n","    print(\"    {}: {}\".format(key, value))"],"metadata":{"id":"AjBvMHtf1chj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = optuna.visualization.plot_param_importances(study)\n","fig.write_image(\"./ActuarialThesis/plots_rgr/myXGBoostRegressorParamImportances.pdf\")\n","fig.show()"],"metadata":{"id":"WUHoqkZc57P-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimized_xgb_rgr = XGBRegressor(**study.best_params)\n","optimized_xgb_rgr.fit(X_train, y_train)\n","y_pred_xgb_rgr = optimized_xgb_rgr.predict(X_val)\n","print('RMSE: ', mean_squared_error(y_val, y_pred_xgb_rgr, squared=False))"],"metadata":{"id":"CbtByQ2h10Wx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from xgboost import plot_importance\n","ax = plot_importance(optimized_xgb_rgr, max_num_features=10)\n","ax.figure.set_size_inches(20, 6)\n","ax.figure.savefig('./ActuarialThesis/plots_rgr/myXGBoostRegressorFeatureImportance.pdf')"],"metadata":{"id":"FHHIx7S66WlJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create two subplots and unpack the output array immediately\n","fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True,  figsize=(15, 4))\n","\n","# Create scatter plot with actual and predicted values\n","sns.scatterplot(ax=ax1, x=y_val, y=y_pred_xgb_rgr)\n","ax1.set_xlabel('Actual Values')\n","ax1.set_ylabel('Predicted Values')\n","ax1.set_title('Actual vs Predicted Values')\n","\n","# Create regression plot with actual and predicted values\n","sns.regplot(ax=ax2, x=y_val, y=y_pred_xgb_rgr, scatter_kws={'s': 10}, line_kws={'color': 'red'})\n","ax2.set_xlabel('Predicted Values')\n","ax2.set_ylabel('Residuals')\n","ax2.set_title('Residual Plot of Actual vs Predicted Values');\n","\n","fig.savefig('./ActuarialThesis/plots_rgr/myXGBoostRegressorActualvsPredicted.pdf')"],"metadata":{"id":"AYzkU5mw6pXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#filename = \"optimized_xgb_rgr.pkl\"\n","#pickle.dump(optimized_xgb_rgr, open(filename, \"wb\"))"],"metadata":{"id":"Ci7Oy_P249o6"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","private_outputs":true},"coursera":{"schema_names":["ensembling-techniques-task-week-2"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}